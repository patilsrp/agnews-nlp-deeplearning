{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† AG-News Topic Classifier using BiLSTM and DistilBERT\n",
    "\n",
    "Complete pipeline for text classification on AG News dataset using Deep Learning.\n",
    "\n",
    "## üìã Table of Contents\n",
    "1. [Setup & Installation](#setup)\n",
    "2. [Data Loading & Preprocessing](#preprocessing)\n",
    "3. [Exploratory Data Analysis](#eda)\n",
    "4. [Model 1: DistilBERT Fine-tuning](#distilbert)\n",
    "5. [Model 2: BiLSTM with Attention](#bilstm)\n",
    "6. [Model Evaluation & Comparison](#evaluation)\n",
    "7. [Interactive Prediction](#prediction)\n",
    "8. [Results Visualization](#visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Google Colab\n",
    "!pip install transformers datasets accelerate -q\n",
    "!pip install wordcloud -q\n",
    "\n",
    "# Upload your data files to Colab\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Create data directory\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "print(\"üìÅ Directories created. Please upload train.csv and test.csv to the data/ folder.\")\n",
    "print(\"üí° Use the file browser on the left to upload your CSV files to data/ directory.\")\n",
    "print(\"üîß Or use the code below to upload files directly:\")\n",
    "print(\"# uploaded = files.upload()  # Uncomment to upload files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm  # Changed for Colab compatibility\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration - Colab GPU detection\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Check if GPU is available and show details\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU available, using CPU (training will be slower)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Preprocessing {#preprocessing}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AGNewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer=None, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.tokenizer:\n",
    "            encoding = self.tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.max_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'text': text,\n",
    "                'input_ids': encoding['input_ids'].flatten(),\n",
    "                'attention_mask': encoding['attention_mask'].flatten(),\n",
    "                'label': torch.tensor(label, dtype=torch.long)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'text': text,\n",
    "                'label': torch.tensor(label, dtype=torch.long)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self):\n",
    "        self.label_mapping = {\n",
    "            1: 0,  # World -> 0\n",
    "            2: 1,  # Sports -> 1\n",
    "            3: 2,  # Business -> 2\n",
    "            4: 3   # Science/Technology -> 3\n",
    "        }\n",
    "        self.class_names = ['World', 'Sports', 'Business', 'Science/Technology']\n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Clean and preprocess text\"\"\"\n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    \n",
    "    def load_data(self, train_path, test_path, sample_size=None):\n",
    "        \"\"\"Load and preprocess AG News data\"\"\"\n",
    "        # Load data\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        \n",
    "        # Set column names\n",
    "        train_df.columns = ['class', 'title', 'description']\n",
    "        test_df.columns = ['class', 'title', 'description']\n",
    "        \n",
    "        # Sample data if specified (for faster training)\n",
    "        if sample_size:\n",
    "            train_df = train_df.sample(n=sample_size, random_state=42)\n",
    "            test_df = test_df.sample(n=min(sample_size//5, len(test_df)), random_state=42)\n",
    "        \n",
    "        # Combine title and description\n",
    "        train_df['text'] = train_df['title'] + ' ' + train_df['description']\n",
    "        test_df['text'] = test_df['title'] + ' ' + test_df['description']\n",
    "        \n",
    "        # Clean text\n",
    "        train_df['text'] = train_df['text'].apply(self.clean_text)\n",
    "        test_df['text'] = test_df['text'].apply(self.clean_text)\n",
    "        \n",
    "        # Map labels\n",
    "        train_df['label'] = train_df['class'].map(self.label_mapping)\n",
    "        test_df['label'] = test_df['class'].map(self.label_mapping)\n",
    "        \n",
    "        return train_df, test_df\n",
    "\n",
    "# Initialize data processor\n",
    "processor = DataProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with sampling for faster training (remove sample_size for full dataset)\n",
    "SAMPLE_SIZE = None  # Increased sample size - adjust as needed (None for full dataset)\n",
    "\n",
    "print(\"üìä Loading AG News dataset...\")\n",
    "try:\n",
    "    train_df, test_df = processor.load_data('data/train.csv', 'data/test.csv', sample_size=SAMPLE_SIZE)\n",
    "    print(f\"‚úÖ Data loaded successfully!\")\n",
    "    print(f\"Training samples: {len(train_df)}\")\n",
    "    print(f\"Test samples: {len(test_df)}\")\n",
    "    print(f\"Classes: {processor.class_names}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Data files not found!\")\n",
    "    print(\"üìÅ Please upload train.csv and test.csv to the data/ directory\")\n",
    "    print(\"üí° You can:\")\n",
    "    print(\"   1. Use the file browser on the left\")\n",
    "    print(\"   2. Or uncomment the file upload code in the first cell\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis {#eda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data\n",
    "print(\"üìù Sample data:\")\n",
    "display(train_df.head())\n",
    "\n",
    "# Class distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "class_counts = train_df['label'].value_counts().sort_index()\n",
    "plt.bar(range(len(processor.class_names)), class_counts.values)\n",
    "plt.title('Training Data - Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(range(len(processor.class_names)), processor.class_names, rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "text_lengths = train_df['text'].str.len()\n",
    "plt.hist(text_lengths, bins=50, alpha=0.7)\n",
    "plt.title('Text Length Distribution')\n",
    "plt.xlabel('Text Length (characters)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(text_lengths.mean(), color='red', linestyle='--', label=f'Mean: {text_lengths.mean():.0f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average text length: {text_lengths.mean():.0f} characters\")\n",
    "print(f\"Max text length: {text_lengths.max():.0f} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/validation split\n",
    "train_texts = train_df['text'].tolist()\n",
    "train_labels = train_df['label'].tolist()\n",
    "test_texts = test_df['text'].tolist()\n",
    "test_labels = test_df['label'].tolist()\n",
    "\n",
    "# Split training data into train/validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_texts, train_labels, test_size=0.1, random_state=42, stratify=train_labels\n",
    ")\n",
    "\n",
    "print(f\"Final splits:\")\n",
    "print(f\"Train: {len(train_texts)} samples\")\n",
    "print(f\"Validation: {len(val_texts)} samples\")\n",
    "print(f\"Test: {len(test_texts)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model 1: DistilBERT Fine-tuning {#distilbert}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DistilBERT tokenizer and model\n",
    "print(\"ü§ñ Loading DistilBERT model...\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased', \n",
    "    num_labels=4\n",
    ").to(device)\n",
    "\n",
    "print(f\"‚úÖ Model loaded and moved to {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "# Adjust batch size based on available memory\n",
    "if torch.cuda.is_available():\n",
    "    BATCH_SIZE = 16  # GPU can handle larger batches\n",
    "else:\n",
    "    BATCH_SIZE = 8   # Smaller for CPU\n",
    "\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "train_dataset = AGNewsDataset(train_texts, train_labels, tokenizer, MAX_LENGTH)\n",
    "val_dataset = AGNewsDataset(val_texts, val_labels, tokenizer, MAX_LENGTH)\n",
    "test_dataset = AGNewsDataset(test_texts, test_labels, tokenizer, MAX_LENGTH)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"üì¶ Created dataloaders with batch size: {BATCH_SIZE}\")\n",
    "print(f\"Total training batches: {len(train_loader)}\")\n",
    "print(f\"‚è±Ô∏è  Estimated training time per epoch: {len(train_loader) * BATCH_SIZE * 0.1 / 60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for DistilBERT\n",
    "def train_distilbert(model, train_loader, val_loader, epochs=3):\n",
    "    # Use AdamW from torch.optim instead of transformers\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nüîÑ Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "                \n",
    "                correct += (predictions == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        val_accuracy = correct / total\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        print(f\"üìä Epoch {epoch+1} - Loss: {avg_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    return train_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DistilBERT model\n",
    "EPOCHS = 5  # Start with 5 epochs for quick training\n",
    "\n",
    "print(f\"üöÄ Starting DistilBERT training for {EPOCHS} epochs...\")\n",
    "train_losses, val_accuracies = train_distilbert(model, train_loader, val_loader, epochs=EPOCHS)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'models/distilbert_model.pth')\n",
    "print(\"üíæ Model saved to models/distilbert_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 2: BiLSTM with Attention {#bilstm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM Model with Attention\n",
    "class BiLSTMAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=100, hidden_dim=256, num_layers=2, num_classes=4, dropout=0.3):\n",
    "        super(BiLSTMAttention, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, \n",
    "                           batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Linear(hidden_dim * 2, 1)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, lengths=None):\n",
    "        # Embedding\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_len, embedding_dim)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)  # (batch_size, seq_len, hidden_dim*2)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attention_weights = torch.softmax(self.attention(lstm_out), dim=1)  # (batch_size, seq_len, 1)\n",
    "        context_vector = torch.sum(attention_weights * lstm_out, dim=1)  # (batch_size, hidden_dim*2)\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(context_vector)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple tokenizer for BiLSTM (word-level)\n",
    "from collections import Counter\n",
    "\n",
    "class SimpleTokenizer:\n",
    "    def __init__(self, max_vocab_size=10000):\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "        self.idx2word = {0: '<PAD>', 1: '<UNK>'}\n",
    "        \n",
    "    def build_vocab(self, texts):\n",
    "        # Count word frequencies\n",
    "        word_counts = Counter()\n",
    "        for text in texts:\n",
    "            words = text.split()\n",
    "            word_counts.update(words)\n",
    "        \n",
    "        # Add most frequent words to vocabulary\n",
    "        most_common = word_counts.most_common(self.max_vocab_size - 2)\n",
    "        \n",
    "        for i, (word, count) in enumerate(most_common):\n",
    "            idx = i + 2  # Start from 2 (after PAD and UNK)\n",
    "            self.word2idx[word] = idx\n",
    "            self.idx2word[idx] = word\n",
    "            \n",
    "        print(f\"Built vocabulary with {len(self.word2idx)} words\")\n",
    "        \n",
    "    def encode(self, texts, max_length=128):\n",
    "        encoded = []\n",
    "        for text in texts:\n",
    "            words = text.split()[:max_length]\n",
    "            indices = [self.word2idx.get(word, 1) for word in words]  # 1 is UNK\n",
    "            \n",
    "            # Pad to max_length\n",
    "            if len(indices) < max_length:\n",
    "                indices.extend([0] * (max_length - len(indices)))  # 0 is PAD\n",
    "                \n",
    "            encoded.append(indices)\n",
    "            \n",
    "        return torch.tensor(encoded, dtype=torch.long)\n",
    "\n",
    "# Build vocabulary and encode texts for BiLSTM\n",
    "bilstm_tokenizer = SimpleTokenizer(max_vocab_size=10000)\n",
    "bilstm_tokenizer.build_vocab(train_texts)\n",
    "\n",
    "# Encode texts\n",
    "train_encoded = bilstm_tokenizer.encode(train_texts, max_length=128)\n",
    "val_encoded = bilstm_tokenizer.encode(val_texts, max_length=128)\n",
    "test_encoded = bilstm_tokenizer.encode(test_texts, max_length=128)\n",
    "\n",
    "print(f\"Encoded shapes - Train: {train_encoded.shape}, Val: {val_encoded.shape}, Test: {test_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BiLSTM datasets and dataloaders\n",
    "class BiLSTMDataset(Dataset):\n",
    "    def __init__(self, encoded_texts, labels):\n",
    "        self.encoded_texts = encoded_texts\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.encoded_texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.encoded_texts[idx],\n",
    "            'label': self.labels[idx]\n",
    "        }\n",
    "\n",
    "bilstm_train_dataset = BiLSTMDataset(train_encoded, train_labels)\n",
    "bilstm_val_dataset = BiLSTMDataset(val_encoded, val_labels)\n",
    "bilstm_test_dataset = BiLSTMDataset(test_encoded, test_labels)\n",
    "\n",
    "bilstm_train_loader = DataLoader(bilstm_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "bilstm_val_loader = DataLoader(bilstm_val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "bilstm_test_loader = DataLoader(bilstm_test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BiLSTM model\n",
    "vocab_size = len(bilstm_tokenizer.word2idx)\n",
    "bilstm_model = BiLSTMAttention(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=100,\n",
    "    hidden_dim=128,\n",
    "    num_layers=2,\n",
    "    num_classes=4,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "print(f\"BiLSTM model initialized with vocab size: {vocab_size}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in bilstm_model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for BiLSTM\n",
    "def train_bilstm(model, train_loader, val_loader, epochs=5):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nüîÑ Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs, attention_weights = model(input_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs, _ = model(input_ids)\n",
    "                predictions = torch.argmax(outputs, dim=-1)\n",
    "                \n",
    "                correct += (predictions == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        val_accuracy = correct / total\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        print(f\"üìä Epoch {epoch+1} - Loss: {avg_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    return train_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train BiLSTM model\n",
    "BILSTM_EPOCHS = 5\n",
    "\n",
    "print(f\"üöÄ Starting BiLSTM training for {BILSTM_EPOCHS} epochs...\")\n",
    "bilstm_train_losses, bilstm_val_accuracies = train_bilstm(bilstm_model, bilstm_train_loader, bilstm_val_loader, epochs=BILSTM_EPOCHS)\n",
    "\n",
    "# Save the model\n",
    "torch.save(bilstm_model.state_dict(), 'models/bilstm_model.pth')\n",
    "print(\"üíæ BiLSTM model saved to models/bilstm_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation & Comparison {#evaluation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, model_type=\"distilbert\"):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=f\"Evaluating {model_type}\"):\n",
    "            if model_type == \"distilbert\":\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            else:  # bilstm\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs, _ = model(input_ids)\n",
    "                predictions = torch.argmax(outputs, dim=-1)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_labels)\n",
    "\n",
    "# Evaluate both models\n",
    "print(\"üìä Evaluating models on test set...\")\n",
    "\n",
    "# DistilBERT evaluation\n",
    "distilbert_preds, distilbert_labels = evaluate_model(model, test_loader, \"distilbert\")\n",
    "distilbert_accuracy = accuracy_score(distilbert_labels, distilbert_preds)\n",
    "\n",
    "# BiLSTM evaluation\n",
    "bilstm_preds, bilstm_labels = evaluate_model(bilstm_model, bilstm_test_loader, \"bilstm\")\n",
    "bilstm_accuracy = accuracy_score(bilstm_labels, bilstm_preds)\n",
    "\n",
    "print(f\"\\nüéØ Test Results:\")\n",
    "print(f\"DistilBERT Accuracy: {distilbert_accuracy:.4f}\")\n",
    "print(f\"BiLSTM Accuracy: {bilstm_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification reports\n",
    "print(\"üìä DistilBERT Classification Report:\")\n",
    "print(classification_report(distilbert_labels, distilbert_preds, target_names=processor.class_names))\n",
    "\n",
    "print(\"\\nüìä BiLSTM Classification Report:\")\n",
    "print(classification_report(bilstm_labels, bilstm_preds, target_names=processor.class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Prediction {#prediction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive prediction function\n",
    "def predict_text(text, use_distilbert=True):\n",
    "    \"\"\"Predict the class of a given text\"\"\"\n",
    "    # Clean text\n",
    "    cleaned_text = processor.clean_text(text)\n",
    "    \n",
    "    if use_distilbert:\n",
    "        # DistilBERT prediction\n",
    "        model.eval()\n",
    "        encoding = tokenizer(\n",
    "            cleaned_text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = encoding['input_ids'].to(device)\n",
    "        attention_mask = encoding['attention_mask'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            probabilities = torch.softmax(outputs.logits, dim=-1)\n",
    "            predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "            confidence = probabilities[0][predicted_class].item()\n",
    "            \n",
    "    else:\n",
    "        # BiLSTM prediction\n",
    "        bilstm_model.eval()\n",
    "        encoded = bilstm_tokenizer.encode([cleaned_text], max_length=128)\n",
    "        input_ids = encoded.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs, attention_weights = bilstm_model(input_ids)\n",
    "            probabilities = torch.softmax(outputs, dim=-1)\n",
    "            predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "            confidence = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    return {\n",
    "        'text': text,\n",
    "        'cleaned_text': cleaned_text,\n",
    "        'predicted_class': processor.class_names[predicted_class],\n",
    "        'confidence': confidence,\n",
    "        'all_probabilities': {processor.class_names[i]: probabilities[0][i].item() for i in range(4)}\n",
    "    }\n",
    "\n",
    "# Test with sample texts\n",
    "sample_texts = [\n",
    "    \"Apple Inc. reports record quarterly earnings with strong iPhone sales\",\n",
    "    \"Scientists discover new exoplanet using advanced telescope technology\",\n",
    "    \"Lakers defeat Warriors in overtime thriller at Staples Center\",\n",
    "    \"Breaking: Political tensions rise as world leaders meet for summit\"\n",
    "]\n",
    "\n",
    "print(\"üîÆ Sample Predictions:\")\n",
    "for text in sample_texts:\n",
    "    print(f\"\\nüìù Text: {text}\")\n",
    "    \n",
    "    # DistilBERT prediction\n",
    "    distilbert_result = predict_text(text, use_distilbert=True)\n",
    "    print(f\"ü§ñ DistilBERT: {distilbert_result['predicted_class']} (confidence: {distilbert_result['confidence']:.3f})\")\n",
    "    \n",
    "    # BiLSTM prediction\n",
    "    bilstm_result = predict_text(text, use_distilbert=False)\n",
    "    print(f\"üß† BiLSTM: {bilstm_result['predicted_class']} (confidence: {bilstm_result['confidence']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive prediction cell - modify the text below to test your own examples\n",
    "YOUR_TEXT = \"Enter your text here for classification\"  # <-- Modify this line\n",
    "\n",
    "print(f\"üîÆ Classifying: '{YOUR_TEXT}'\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Get predictions from both models\n",
    "distilbert_result = predict_text(YOUR_TEXT, use_distilbert=True)\n",
    "bilstm_result = predict_text(YOUR_TEXT, use_distilbert=False)\n",
    "\n",
    "print(f\"ü§ñ DistilBERT Prediction:\")\n",
    "print(f\"   Class: {distilbert_result['predicted_class']}\")\n",
    "print(f\"   Confidence: {distilbert_result['confidence']:.3f}\")\n",
    "print(f\"   All probabilities: {distilbert_result['all_probabilities']}\")\n",
    "\n",
    "print(f\"\\nüß† BiLSTM Prediction:\")\n",
    "print(f\"   Class: {bilstm_result['predicted_class']}\")\n",
    "print(f\"   Confidence: {bilstm_result['confidence']:.3f}\")\n",
    "print(f\"   All probabilities: {bilstm_result['all_probabilities']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "agreement = \"‚úÖ AGREE\" if distilbert_result['predicted_class'] == bilstm_result['predicted_class'] else \"‚ùå DISAGREE\"\n",
    "print(f\"Models {agreement} on classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results Visualization {#visualization}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves comparison\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Training losses\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, 'b-', label='DistilBERT', marker='o')\n",
    "plt.plot(range(1, len(bilstm_train_losses)+1), bilstm_train_losses, 'r-', label='BiLSTM', marker='s')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Validation accuracies\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(range(1, len(val_accuracies)+1), val_accuracies, 'b-', label='DistilBERT', marker='o')\n",
    "plt.plot(range(1, len(bilstm_val_accuracies)+1), bilstm_val_accuracies, 'r-', label='BiLSTM', marker='s')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Final comparison\n",
    "plt.subplot(1, 3, 3)\n",
    "models = ['DistilBERT', 'BiLSTM']\n",
    "accuracies = [distilbert_accuracy, bilstm_accuracy]\n",
    "colors = ['skyblue', 'lightcoral']\n",
    "\n",
    "bars = plt.bar(models, accuracies, color=colors, alpha=0.7)\n",
    "plt.title('Test Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# DistilBERT confusion matrix\n",
    "plt.subplot(1, 2, 1)\n",
    "cm_distilbert = confusion_matrix(distilbert_labels, distilbert_preds)\n",
    "sns.heatmap(cm_distilbert, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=processor.class_names, yticklabels=processor.class_names)\n",
    "plt.title('DistilBERT Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# BiLSTM confusion matrix\n",
    "plt.subplot(1, 2, 2)\n",
    "cm_bilstm = confusion_matrix(bilstm_labels, bilstm_preds)\n",
    "sns.heatmap(cm_bilstm, annot=True, fmt='d', cmap='Reds',\n",
    "            xticklabels=processor.class_names, yticklabels=processor.class_names)\n",
    "plt.title('BiLSTM Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary and final results\n",
    "print(\"üéØ FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"üìä Dataset: AG News Classification\")\n",
    "print(f\"üî¢ Classes: {len(processor.class_names)} ({', '.join(processor.class_names)})\")\n",
    "print(f\"üìà Training samples: {len(train_texts):,}\")\n",
    "print(f\"üîç Test samples: {len(test_texts):,}\")\n",
    "print(f\"üíª Device: {device}\")\n",
    "\n",
    "print(f\"\\nü§ñ DistilBERT Model:\")\n",
    "print(f\"   ‚Ä¢ Architecture: DistilBERT-base-uncased fine-tuned\")\n",
    "print(f\"   ‚Ä¢ Parameters: ~66M\")\n",
    "print(f\"   ‚Ä¢ Test Accuracy: {distilbert_accuracy:.4f} ({distilbert_accuracy*100:.2f}%)\")\n",
    "print(f\"   ‚Ä¢ Training Epochs: {EPOCHS}\")\n",
    "\n",
    "print(f\"\\nüß† BiLSTM Model:\")\n",
    "print(f\"   ‚Ä¢ Architecture: BiLSTM + Attention\")\n",
    "print(f\"   ‚Ä¢ Vocabulary Size: {vocab_size:,}\")\n",
    "print(f\"   ‚Ä¢ Parameters: {sum(p.numel() for p in bilstm_model.parameters()):,}\")\n",
    "print(f\"   ‚Ä¢ Test Accuracy: {bilstm_accuracy:.4f} ({bilstm_accuracy*100:.2f}%)\")\n",
    "print(f\"   ‚Ä¢ Training Epochs: {BILSTM_EPOCHS}\")\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {'DistilBERT' if distilbert_accuracy > bilstm_accuracy else 'BiLSTM'}\")\n",
    "print(f\"üéØ Performance Difference: {abs(distilbert_accuracy - bilstm_accuracy)*100:.2f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ All models trained and evaluated successfully!\")\n",
    "print(\"üíæ Models saved in 'models/' directory\")\n",
    "print(\"üìä Ready for deployment or further analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
